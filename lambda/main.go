package main

import (
	"bytes"
	"context"
	"errors"
	"fmt"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"time"

	"github.com/aws/aws-lambda-go/lambda"
	"github.com/aws/aws-sdk-go/aws"
	"github.com/aws/aws-sdk-go/aws/session"
	"github.com/aws/aws-sdk-go/service/cloudfront"
	"github.com/aws/aws-sdk-go/service/s3"
	"github.com/aws/aws-sdk-go/service/s3/s3manager"
	"github.com/deepfactor-io/exploitdb/commands"
	"github.com/deepfactor-io/exploitdb/util"
)

var (
	AWS_S3_REGION       = os.Getenv("AWS_S3_REGION")
	AWS_S3_BUCKET       = os.Getenv("AWS_S3_BUCKET")
	EXPLOITDB_FILE_NAME = os.Getenv("EXPLOITDB_FILE_NAME")
	EXPLOITDB_DIR       = filepath.Join(util.CacheDir(), EXPLOITDB_FILE_NAME)
	CLOUDFRONT_DIST_ID  = os.Getenv("CLOUDFRONT_DIST_ID")
)

func main() {
	lambda.Start(HandleRequest)
}

func HandleRequest(ctx context.Context) error {
	session, err := session.NewSession(&aws.Config{Region: aws.String(AWS_S3_REGION)})
	if err != nil {
		log.Printf("error while creating a connection session for Region:%s, Error:%s", AWS_S3_REGION, err)
	}

	// 	// download latest sqlite db file from s3
	// this is to handle scenarios where we have a problem fetching data from some sources
	// Old data can be kept intact
	var s3DownloadFailure bool
	err = downloadFileFromS3(session, EXPLOITDB_DIR)
	if err != nil {
		log.Printf("error while downloading exploit db file from s3. Bucket:%s, Region:%s, File:%s,,Error:%s", AWS_S3_BUCKET, AWS_S3_REGION, EXPLOITDB_FILE_NAME, err)
		s3DownloadFailure = true
	}

	// gather latest exploit info from different sources
	isComplete, err := commands.FetchAllDB()
	if err != nil {
		return err
	}

	if !isComplete && s3DownloadFailure {
		return errors.New("skipping db update due to s3 download failure while updating latest exploit info")
	}
	// Upload updated sqlite db file to s3
	err = uploadFileToS3(session, EXPLOITDB_DIR)
	if err != nil {
		log.Printf("error while uploading exploit db file to s3. Bucket:%s, Region:%s,Error:%s", AWS_S3_BUCKET, AWS_S3_REGION, err)
		return err
	}

	// Invalidate CloudFront cache for the uploaded file
	err = invalidateCloudFrontCache(session)
	if err != nil {
		log.Printf("error while invalidating CloudFront cache. DistributionID:%s, Error:%s", CLOUDFRONT_DIST_ID, err)
	}

	return err
}

func uploadFileToS3(session *session.Session, uploadFileDir string) error {

	upFile, err := os.Open(uploadFileDir)
	if err != nil {
		return err
	}
	defer upFile.Close()

	upFileInfo, _ := upFile.Stat()
	var fileSize int64 = upFileInfo.Size()
	fileBuffer := make([]byte, fileSize)
	upFile.Read(fileBuffer)

	_, err = s3.New(session).PutObject(&s3.PutObjectInput{
		Bucket:               aws.String(AWS_S3_BUCKET),
		Key:                  aws.String(EXPLOITDB_FILE_NAME),
		Body:                 bytes.NewReader(fileBuffer),
		ContentLength:        aws.Int64(fileSize),
		ContentType:          aws.String(http.DetectContentType(fileBuffer)),
		ContentDisposition:   aws.String("attachment"),
		ServerSideEncryption: aws.String("AES256"),
	})

	return err
}

func downloadFileFromS3(session *session.Session, fileDir string) error {
	err := os.Mkdir(util.CacheDir(), os.ModePerm)
	if err != nil {
		return err
	}

	file, err := os.Create(fileDir)
	if err != nil {
		return err
	}

	defer file.Close()

	downloader := s3manager.NewDownloader(session)

	size, err := downloader.Download(file,
		&s3.GetObjectInput{
			Bucket: aws.String(AWS_S3_BUCKET),
			Key:    aws.String(EXPLOITDB_FILE_NAME),
		})

	if size == 0 {
		return errors.New(fmt.Sprintf("Couldn't download file from s3. Error:%s", err))
	}

	return err
}

func invalidateCloudFrontCache(session *session.Session) error {
	cf := cloudfront.New(session)

	paths := &cloudfront.Paths{
		Items:    []*string{aws.String("/" + EXPLOITDB_FILE_NAME)},
		Quantity: aws.Int64(1),
	}

	_, err := cf.CreateInvalidation(&cloudfront.CreateInvalidationInput{
		DistributionId: aws.String(CLOUDFRONT_DIST_ID),
		InvalidationBatch: &cloudfront.InvalidationBatch{
			CallerReference: aws.String(time.Now().String()),
			Paths:           paths,
		},
	})

	return err
}
